{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20219e6d-77c3-4094-aa08-9adcc2db8123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import UsefulFunctions as uf\n",
    "import pygmt\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from pyproj import Transformer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fc8a96c-adc8-40da-b734-6358393800e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions needed for making the big grid and calculating distances (vectorized haversine + pythagorean theorem for 3d distance)\n",
    "\n",
    "def trunc_float(nums, dec):\n",
    "    truncated_nums = np.trunc(nums*10**dec)/10**dec\n",
    "    \n",
    "    return truncated_nums\n",
    "\n",
    "def generate_grid(min_lat, max_lat, min_lon, max_lon, spacing_km):\n",
    "    # convert km spacing to degrees, use average lat for longitude spacing\n",
    "    lat_degree_spacing = trunc_float(spacing_km/111, 5)\n",
    "    avg_lat = min_lat + (max_lat - min_lat)/2\n",
    "    lon_degree_spacing = trunc_float(spacing_km/(111*np.cos(np.radians(avg_lat))), 5)\n",
    "    \n",
    "    lats = np.arange(min_lat, max_lat + lat_degree_spacing, lat_degree_spacing)\n",
    "    lons = np.arange(min_lon, max_lon + lon_degree_spacing, lon_degree_spacing)\n",
    "    lons_2d, lats_2d = np.meshgrid(lons, lats)\n",
    "    grid = np.hstack((lats_2d.flatten().reshape(-1,1), lons_2d.flatten().reshape(-1,1)))\n",
    "\n",
    "    return grid, lats, lons\n",
    "\n",
    "\n",
    "def calculate_3d_distances(grid, other_points, depth):\n",
    "    grid_latitudes = np.radians(grid[:, 0])\n",
    "    grid_longitudes = np.radians(grid[:, 1])\n",
    "    other_latitudes = np.radians(other_points[:, 0])\n",
    "    other_longitudes = np.radians(other_points[:, 1])\n",
    "\n",
    "    dlat = other_latitudes[:, None] - grid_latitudes\n",
    "    dlon = other_longitudes[:, None] - grid_longitudes\n",
    "\n",
    "    a = np.sin(dlat/2)**2 + np.cos(other_latitudes[:, None]) * np.cos(grid_latitudes) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    distances_2d = 6371 * c  # 2D distances on the Earth's surface\n",
    "\n",
    "    # Calculate 3D distances by adding depth component\n",
    "    distances_3d = np.sqrt(distances_2d**2 + depth**2)\n",
    "\n",
    "    return distances_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "329dbc79-b7dc-49d3-ad02-59731d61a5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized functions needed for checking angles for a mass number of earthquake sources\n",
    "\n",
    "def spherical_to_cartesian(lat, lon, depth):\n",
    "    # Convert spherical coordinates (latitude, longitude, depth) to Cartesian coordinates (x, y, z)\n",
    "    # lat_rad = np.radians(lat)\n",
    "    # lon_rad = np.radians(lon)\n",
    "    # x = np.cos(lat_rad) * np.cos(lon_rad) * (6371 - depth)\n",
    "    # y = np.cos(lat_rad) * np.sin(lon_rad) * (6371 - depth)\n",
    "    # z = np.sin(lat_rad) * (6371 - depth)\n",
    "    \n",
    "    # Just use a transformer from pyproj  (WGS84 > WGS Geocentric (XYZ))\n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:4978\")\n",
    "    x, y, z = transformer.transform(lat, lon, depth)  # outputs in m\n",
    "\n",
    "    return np.array([x, y, z]).T/1000. # convert back to km, transpose for columns instead of rows\n",
    "\n",
    "\n",
    "def compute_3d_angles(stations, sources):\n",
    "    # Convert stations and sources to Cartesian coordinates\n",
    "    stations_cartesian = np.array([spherical_to_cartesian(*station) for station in stations])\n",
    "    sources_cartesian = np.array([spherical_to_cartesian(*source) for source in sources])\n",
    "    print(stations_cartesian.shape)\n",
    "    print(sources_cartesian.shape)\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "# Assuming stations is a NumPy array of shape (n, 3) containing (latitude, longitude, depth) coordinates of stations\n",
    "# and sources is a NumPy array of shape (m, 3) containing (latitude, longitude, depth) coordinates of sources\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d31f13b-b82e-4eeb-a886-ad0d2d674f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_detection_time(grid, stations_coords, depth, velP):\n",
    "    max_gap = 60\n",
    "    min_angle = 60\n",
    "    # get distances to each station for each point\n",
    "    distances_3d = calculate_3d_distances(grid, stations_coords, depth) \n",
    "    \n",
    "#     sta_coords_cart = spherical_to_cartesian(stations_coords[:,0], stations_coords[:,1], stations_coords[:,2])\n",
    "#     grid_coords_cart = spherical_to_cartesian(grid[:,0], grid[:,1], grid[:,2])\n",
    "\n",
    "#     #initialize grid for stacking data\n",
    "#     dists_and_sta_coords = np.empty((len(stations_coords), len(grid), 4))\n",
    "#     # first pane is distance\n",
    "#     dists_and_sta_coords[:,:,0] = distances_3d\n",
    "#     # next 3 panes are coords\n",
    "#     dists_and_sta_coords[:,:,1] = np.tile(sta_coords_cart[:, 0].reshape(-1,1), len(grid))\n",
    "#     dists_and_sta_coords[:,:,2] = np.tile(sta_coords_cart[:, 1].reshape(-1,1), len(grid))\n",
    "#     dists_and_sta_coords[:,:,3] = np.tile(sta_coords_cart[:, 2].reshape(-1,1), len(grid))\n",
    "\n",
    "#     # sort columns of first panel (distances) and get the indices to use to reconstruct sorted array\n",
    "#     ai = np.argsort(dists_and_sta_coords[:, :, 0], axis=0)\n",
    "#     # initialize the new sorted array\n",
    "#     dsc_sorted = np.empty((len(stations_coords), len(grid), 4))\n",
    "#     # first pane is distance, next 3 are coords, same as before but sorted using the indices from argsort\n",
    "#     dsc_sorted[:,:,0] = np.take_along_axis(dists_and_sta_coords[:,:,0], ai, axis=0)\n",
    "#     dsc_sorted[:,:,1] = np.take_along_axis(dists_and_sta_coords[:,:,1], ai, axis=0)\n",
    "#     dsc_sorted[:,:,2] = np.take_along_axis(dists_and_sta_coords[:,:,2], ai, axis=0)\n",
    "#     dsc_sorted[:,:,3] = np.take_along_axis(dists_and_sta_coords[:,:,3], ai, axis=0)\n",
    "    \n",
    "#     # tile the grid coords so each point can be subtracted from each station coord (like a 3d meshgrid)\n",
    "#     grid_tiled = np.empty((len(stations_coords), len(grid), 3))\n",
    "#     grid_tiled[:, :, 0] = np.tile(grid_coords_cart[:, 0].reshape(-1, 1), len(stations_coords)).T\n",
    "#     grid_tiled[:, :, 1] = np.tile(grid_coords_cart[:, 1].reshape(-1, 1), len(stations_coords)).T\n",
    "#     grid_tiled[:, :, 2] = np.tile(grid_coords_cart[:, 2].reshape(-1, 1), len(stations_coords)).T    \n",
    "    \n",
    "#     # subtract each grid point coords from each station coords to get all displacement vectors\n",
    "#     displacement_vectors_array = dsc_sorted[:, :, 1:] - grid_tiled\n",
    "    \n",
    "#     n = 4\n",
    "#     # get dot products for first n stations\n",
    "#     angles = np.ones(shape=(1,len(grid))) * np.radians(180)\n",
    "#     dva_first_n = displacement_vectors_array[:n, :, :]\n",
    "#     for i in range(n):\n",
    "#         mag_i_arr = np.linalg.norm(dva_first_n[i,:,:], axis=1)\n",
    "#         for j in range(i+1, n):\n",
    "#             dot_prod_arr = np.sum(dva_first_n[i,:,:] * dva_first_n[j,:,:], axis=1)\n",
    "#             mag_j_arr = np.linalg.norm(dva_first_n[j,:,:], axis=1)\n",
    "#             mag_ij_arr = mag_i_arr * mag_j_arr\n",
    "#             cos_angles = dot_prod_arr/mag_ij_arr\n",
    "#             angles = np.vstack((angles, np.arccos(cos_angles).reshape(1,-1)))\n",
    "#     # check which columns have an angle that meets the min_angle, then fill in other array\n",
    "    \n",
    "    \n",
    "    detection_times_all = distances_3d/velP\n",
    "    detection_times = np.sort(detection_times_all.T)[:, 3]\n",
    "    return detection_times\n",
    "    # return angles, dsc_sorted  # in radians\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48f14440-c011-48d3-9abe-7ebd4e8029fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_blind_zone_radius(det_times, velS, d):\n",
    "    R = (det_times + 4) * velS  # raidus of the travel distance sphere around the hypocenter\n",
    "    r = np.sqrt((R**2 - d**2))  # radius of blind zone, if R < d then blind zone will be a complex num\n",
    "    r[np.isnan(r)] = 0  #replace compelx nums with 0\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "637df1b2-0a9e-4d4e-9fe5-55339e199331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourth_closest_station(grid, stations, depth):\n",
    "    d3d = calculate_3d_distances(grid, stations, depth)\n",
    "    d3d_sort = np.sort(d3d, axis=1)\n",
    "    d3d_4c = d3d_sort[:, 3]\n",
    "    return d3d_4c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3c3044e4-e3ac-465e-987d-c1797ee2bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 0\n",
    "velP = uf.Earthquake.vel_p\n",
    "velS = uf.Earthquake.vel_s\n",
    "\n",
    "# Proposed network\n",
    "# stations = pd.read_csv('Data/EEWNetwork.csv')\n",
    "# stations_coords = np.vstack((stations.Lat, stations.Lon, np.zeros(shape=stations.Lat.shape))).T\n",
    "\n",
    "# my list none closer than 10km\n",
    "stations = uf.ActiveBBs\n",
    "stations_coords = np.vstack((stations.lat, stations.lon, np.zeros(shape=stations.lat.shape))).T\n",
    "\n",
    "# stations cut from all bbs to get my list\n",
    "stations_cut = pd.read_csv('Data/stations_Cut.csv')\n",
    "stations = pd.concat([stations,stations_cut],ignore_index=True)\n",
    "stations_coords = np.vstack((stations.lat, stations.lon, np.zeros(shape=stations.lat.shape))).T\n",
    "\n",
    "stations = np.genfromtxt('Data/activeBBs.txt',\n",
    "                          delimiter=[8, 9, 12, 8, 50],\n",
    "                          # encoding='utf-8',\n",
    "                          dtype=[('sta', 'U5'), ('lat', 'f8'), ('lon', 'f8'), ('elev', 'f8'), ('staname', 'U50')],\n",
    "                          # usecols=(0, 1, 2, 3),\n",
    "                          autostrip=True,\n",
    "                          )\n",
    "stlats = np.array([[st[1] for st in stations]])\n",
    "stlons = np.array([[st[2] for st in stations]])\n",
    "stations_coords = np.vstack((stlats, stlons, np.zeros(shape=stlats.shape))).T\n",
    "\n",
    "# Define the bounding box and spacing\n",
    "min_lat = 49.5\n",
    "max_lat = 72\n",
    "min_lon = -196\n",
    "max_lon = -129\n",
    "spacing_km = 10  # Adjust as needed\n",
    "\n",
    "# Generate the grid\n",
    "grid, lats, lons = generate_grid(min_lat, max_lat, min_lon, max_lon, spacing_km)\n",
    "grid = np.hstack((grid, np.ones((len(grid), 1)) * depth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dfc15393-8493-4d05-b279-f6ed4db4f415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(616, 3)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a318d467-0f0b-4fae-8219-09c5b7a69724",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_3d = calculate_3d_distances(grid, stations_coords, depth) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b6d6b0e5-73f0-4006-9394-4f726f3f8165",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_times = calculate_detection_time(grid, stations_coords, depth, velP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7341b2f0-d98d-4e8b-8ae8-a4cf4ab34a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bz_rs = calculate_blind_zone_radius(detection_times, velS, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ea741e64-5ff7-4872-bdb3-89a0797083ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# data = bz_rs.reshape(len(lats), -1)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistances_3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mlen\u001b[39m(lats), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m gridBoundaries \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-158/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_lon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/52/66\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36msort\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ShakeMaps/lib/python3.9/site-packages/numpy/core/fromnumeric.py:998\u001b[0m, in \u001b[0;36msort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    997\u001b[0m     a \u001b[38;5;241m=\u001b[39m asanyarray(a)\u001b[38;5;241m.\u001b[39mcopy(order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 998\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# data = bz_rs.reshape(len(lats), -1)\n",
    "data = np.sort(distances_3d.T)[:, 3].reshape(len(lats), -1)\n",
    "print(data.shape)\n",
    "gridBoundaries = f'-158/{max_lon}/52/66'\n",
    "# gridBoundaries = f'{min_lon}/{max_lon}/{min_lat}/{max_lat}'\n",
    "\n",
    "title = f\"Fourth Closest Station {depth} km (All BB)\"\n",
    "coast_border = \"a/0.5p,brown\"\n",
    "shorelines = \"0.3p,black\"\n",
    "projection = 'M15c'\n",
    "fig = pygmt.Figure()\n",
    "# fig.basemap(region='170/49/-128/73+r', projection='M15c', frame=[\"af\", f'WSne+t\"{title}\"'])\n",
    "# fig.basemap(region=gridBoundaries, projection=projection, frame=[\"af\", f'WSne+t\"{title}\"'], map_scale=\"jBL+w500k+o1c/1c+f\")\n",
    "fig.basemap(region=gridBoundaries, projection=projection, frame=[\"af\", f'WSne+t\"{title}\"'])\n",
    "\n",
    "fig.coast(shorelines=shorelines, borders=coast_border, water='skyblue', land='lightgray')  # draw coast over datawater='skyblue'\n",
    "\n",
    "vmin = 0\n",
    "vmax = 200\n",
    "pygmt.makecpt(\n",
    "    cmap=['seis'],\n",
    "    reverse=True,\n",
    "    series=[vmin, vmax],\n",
    "    no_bg=True\n",
    "    )\n",
    "\n",
    "data_array = xr.DataArray(data=data, \n",
    "                          dims=['lat', 'lon'],\n",
    "                          coords=dict(lon=(['lon'], lons),\n",
    "                                      lat=(['lat'], lats)))\n",
    "\n",
    "# masked_data_array = xr.where((data_array < vmin) | (data_array > vmax), np.nan, data_array)\n",
    "\n",
    "fig.grdimage(grid=data_array,\n",
    "             projection=projection,\n",
    "             region=gridBoundaries,\n",
    "             cmap=True, \n",
    "             transparency=40)\n",
    "\n",
    "fig.plot(  # Plot seismic stations as triangles\n",
    "    x=stations['lon'],\n",
    "    y=stations['lat'],\n",
    "    style='t+0.2c',\n",
    "    color='white',\n",
    "    pen='black',\n",
    ")\n",
    "\n",
    "with open('Data/Interior Crustal/Old Interior Community Data.json') as json_file:\n",
    "    comm_dict = json.load(json_file)\n",
    "# plot communities\n",
    "for name, data in comm_dict.items():\n",
    "    if name in ['Glennallen', 'North Pole', 'Eielson Air Force Base', 'Clear Space Force Station', 'Fort Wainwright', 'Fort Greely', 'Cantwell']:\n",
    "        continue\n",
    "    fig.plot(\n",
    "        x=data['latlon'][1],\n",
    "        y=data['latlon'][0],\n",
    "        style='c0.16c',\n",
    "        color='black'\n",
    "    )\n",
    "    if name.lower() in ['anchorage']:\n",
    "        corner = 'BR'\n",
    "        adjust = 0.025\n",
    "    elif name.lower() in ['whittier']:\n",
    "        corner = 'TR'\n",
    "        adjust = -0.05\n",
    "    else:\n",
    "        corner = 'BR'\n",
    "        adjust = 0.025\n",
    "    fig.text(\n",
    "        x=data['latlon'][1],\n",
    "        y=data['latlon'][0] + adjust,\n",
    "        text=name,\n",
    "        font='14p,Helvetica-Narrow-Bold,black,=0.5p,white',\n",
    "        justify=corner\n",
    "    )\n",
    "others = [('Kodiak', 57.7900, -152.4072), ('Valdez', 61.1309, -146.3499), ('Juneau', 58.3005, -134.4201)]\n",
    "for comm in others:\n",
    "    name = comm[0]\n",
    "    lat = comm[1]\n",
    "    lon = comm[2]\n",
    "    if name in ['Juneau', 'Valdez']:\n",
    "        corner = 'BL'\n",
    "    fig.plot(\n",
    "            x=lon,\n",
    "            y=lat,\n",
    "            style='c0.16c',\n",
    "            color='black'\n",
    "        )\n",
    "    fig.text(\n",
    "            x=lon,\n",
    "            y=lat + adjust,\n",
    "            text=name,\n",
    "            font='14p,Helvetica-Narrow-Bold,black,=0.5p,white',\n",
    "            justify=corner\n",
    "        )\n",
    "\n",
    "fig.colorbar(\n",
    "    position='g-141/52.5+w3c/0.5c+v',\n",
    "    frame=['x','ya5f2.5+lkm']\n",
    ")\n",
    "fig.basemap(region=gridBoundaries, projection=projection, map_scale=\"g-146/53+w200k+f+lkm\")\n",
    "\n",
    "fig.show()\n",
    "fig.savefig(f'Figures/misc/Fourth Closest Station {depth} km All BB.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05bfa74-a790-43c3-a295-7a7c890c7907",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridBoundaries = f'{min_lon-0.5}/{max_lon+0.5}/{min_lat-0.5}/{max_lat+0.5}'\n",
    "title = f\"Detection Times at {depth} km Depth\"\n",
    "coast_border = \"a/0.5p,brown\"\n",
    "shorelines = \"0.3p,black\"\n",
    "fig = pygmt.Figure()\n",
    "# fig.basemap(region='170/49/-128/73+r', projection='M15c', frame=[\"af\", f'WSne+t\"{title}\"'])\n",
    "fig.basemap(region=gridBoundaries, projection='M15c', frame=[\"af\", f'WSne+t\"{title}\"'])\n",
    "\n",
    "fig.coast(shorelines=shorelines, borders=coast_border, water='skyblue', land='lightgray')  # draw coast over datawater='skyblue'\n",
    "\n",
    "pygmt.makecpt(\n",
    "    transparency=75,\n",
    "    cmap=['seis'],\n",
    "    reverse=True,\n",
    "    series=[0, 60]  # np.max(p[2, :])\n",
    ")\n",
    "data_array = xr.DataArray(data=dt_2d, \n",
    "                          dims=['lat', 'lon'],\n",
    "                          coords=dict(lon=(['lon'], lons),\n",
    "                                      lat=(['lat'], lats)))\n",
    "fig.grdimage(grid=data_array,\n",
    "             projection='M15c',\n",
    "             region=gridBoundaries,\n",
    "             cmap=True)\n",
    "\n",
    "fig.plot(  # Plot seismic stations as triangles\n",
    "    x=stations['lon'],\n",
    "    y=stations['lat'],\n",
    "    style='t+0.3c',\n",
    "    color='white',\n",
    "    pen='black',\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.savefig(f'Figures/misc/detection time map {depth} km depth.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa046ff-da7c-4a46-b00d-ef85681029b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sta_lats = np.array(stations['lat'])\n",
    "# sta_lons = np.array(stations['lon'])\n",
    "# print(np.array(stations['lon']).shape)\n",
    "# num_p = len(grid_lons)\n",
    "# num_sta = len(sta_lons)\n",
    "# grid_lons_2D = np.reshape(grid_lons, (num_p, 1))\n",
    "# grid_lats_2D = np.reshape(grid_lats, (num_p, 1))\n",
    "\n",
    "# sta_lons_2D = np.zeros(shape=(num_p, num_sta))\n",
    "# sta_lats_2D = np.zeros(shape=(num_p, num_sta))\n",
    "# for i in range(num_p):\n",
    "#     sta_lons_2D[i,:] = sta_lons\n",
    "#     sta_lats_2D[i,:] = sta_lats\n",
    "# print(grid_lons_2D.shape)\n",
    "# print(sta_lons_2D.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
